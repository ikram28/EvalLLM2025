{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Aligning the LLM output with the original text"
      ],
      "metadata": {
        "id": "l0Xfo3uEeNr_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GV6-s4p-b4SQ"
      },
      "outputs": [],
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "\n",
        "def align_entities_to_original(original_text, llm_output):\n",
        "    if \"```\" in llm_output:\n",
        "        content = llm_output.split(\"```\")[1]\n",
        "        if content.startswith(\"xml\"):\n",
        "            content = content[3:].strip()\n",
        "    else:\n",
        "        content = llm_output\n",
        "\n",
        "    result = original_text\n",
        "    tag_stack = []\n",
        "    entity_markers = []\n",
        "\n",
        "    # First pass: Extract tag positions from the LLM output\n",
        "    i = 0\n",
        "    clean_llm_text = \"\"\n",
        "    while i < len(content):\n",
        "        if content[i] == '<':\n",
        "            tag_start = i\n",
        "            i += 1\n",
        "            while i < len(content) and content[i] != '>':\n",
        "                i += 1\n",
        "\n",
        "            if i < len(content):\n",
        "                tag_content = content[tag_start:i+1]\n",
        "\n",
        "                if tag_content.startswith(\"</\"):\n",
        "                    tag_name = tag_content[2:-1]\n",
        "                    if tag_stack and tag_stack[-1][0] == tag_name:\n",
        "                        open_tag_name, open_pos = tag_stack.pop()\n",
        "                        entity_text = clean_llm_text[open_pos:]\n",
        "                        entity_markers.append((open_pos, len(clean_llm_text), entity_text, open_tag_name))\n",
        "                else:\n",
        "                    tag_name = tag_content[1:-1]\n",
        "                    tag_stack.append((tag_name, len(clean_llm_text)))\n",
        "        else:\n",
        "            clean_llm_text += content[i]\n",
        "        i += 1\n",
        "\n",
        "    # Second pass: Find the corresponding positions in the original text\n",
        "    matcher = SequenceMatcher(None, clean_llm_text, original_text)\n",
        "\n",
        "    position_map = {}\n",
        "    for block in matcher.get_matching_blocks():\n",
        "        for i in range(block.size):\n",
        "            position_map[block.a + i] = block.b + i\n",
        "\n",
        "    entity_markers.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    for start_pos, end_pos, entity_text, tag_name in entity_markers:\n",
        "        if start_pos in position_map and (end_pos - 1) in position_map:\n",
        "            orig_start = position_map[start_pos]\n",
        "            orig_end = position_map[end_pos - 1] + 1\n",
        "\n",
        "            result = result[:orig_end] + f\"</{tag_name}>\" + result[orig_end:]\n",
        "            result = result[:orig_start] + f\"<{tag_name}>\" + result[orig_start:]\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('input-file.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "for entry in data:\n",
        "    text = entry.get('text', '')\n",
        "    print(text)\n",
        "    pred = entry.get('prediction', '')\n",
        "    print(pred)\n",
        "    entry['aligned'] = align_entities_to_original(text, pred)\n",
        "    print( entry['aligned'])\n",
        "\n",
        "with open('input-file_aligned.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, ensure_ascii=False, indent=2)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0AOnN0kOV9s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to the json format (Detagging)"
      ],
      "metadata": {
        "id": "lU-P9qN5fQ6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "def _auto_id():\n",
        "    return f\"U{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "import re, uuid\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "OPEN_RE  = re.compile(r'<([A-Z_]+)(?:\\s+ent_id=\"([^\"]+)\")?>')\n",
        "CLOSE_RE = re.compile(r'</([A-Z_]+)>')\n",
        "\n",
        "def detag_to_entities(tagged: str) -> List[Dict[str, Any]]:\n",
        "    plain_chars: List[str] = []\n",
        "    stack: List[tuple] = []\n",
        "    by_id: Dict[str, Dict[str, Any]] = {}\n",
        "\n",
        "    def _auto_id():\n",
        "        return f\"U{uuid.uuid4().hex[:8]}\"\n",
        "\n",
        "    i = 0\n",
        "    N = len(tagged)\n",
        "    while i < N:\n",
        "        mo = OPEN_RE.match(tagged, i)\n",
        "        if mo:\n",
        "            label, eid = mo.group(1), mo.group(2)\n",
        "            stack.append((label, eid, len(plain_chars)))\n",
        "            i = mo.end()\n",
        "            continue\n",
        "\n",
        "        mc = CLOSE_RE.match(tagged, i)\n",
        "        if mc:\n",
        "            label = mc.group(1)\n",
        "            while stack and stack[-1][0] != label:\n",
        "                stack.pop()\n",
        "            if stack:\n",
        "                label, eid, start = stack.pop()\n",
        "                end = len(plain_chars)\n",
        "                part_text = \"\".join(plain_chars[start:end])\n",
        "                if eid is None:\n",
        "                    eid = _auto_id()\n",
        "                rec = by_id.setdefault(\n",
        "                    eid,\n",
        "                    {\"label\": label, \"id\": eid,\n",
        "                     \"text_parts\": [], \"start\": [], \"end\": []})\n",
        "                rec[\"text_parts\"].append(part_text)\n",
        "                rec[\"start\"].append(start)\n",
        "                rec[\"end\"].append(end)\n",
        "            i = mc.end()\n",
        "            continue\n",
        "\n",
        "        plain_chars.append(tagged[i])\n",
        "        i += 1\n",
        "\n",
        "    plain = \"\".join(plain_chars)\n",
        "\n",
        "    out = []\n",
        "    for rec in by_id.values():\n",
        "        order = sorted(range(len(rec[\"start\"])), key=lambda k: rec[\"start\"][k])\n",
        "        joined = \" \".join(rec[\"text_parts\"][k] for k in order)\n",
        "        out.append({\n",
        "            \"text\":  joined,\n",
        "            \"start\": rec[\"start\"],\n",
        "            \"end\":   rec[\"end\"],\n",
        "            \"id\":    rec[\"id\"],\n",
        "            \"label\": rec[\"label\"],\n",
        "        })\n",
        "    return out\n",
        "\n"
      ],
      "metadata": {
        "id": "ppH0WbarfKki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('input-file_aligned.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "for entry in data:\n",
        "    text = entry.get('text', '')\n",
        "    pred = entry.get('aligned', '')\n",
        "    entry['entities'] =  detag_to_entities(pred)\n",
        "\n",
        "with open('input-file_detagged.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(data, f, ensure_ascii=False, indent=2)\n"
      ],
      "metadata": {
        "id": "LJhnewW-bWnA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}