{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#  ========== INSTALL DEPENDENCIES =========="
      ],
      "metadata": {
        "id": "CeozWDB2cZ3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "PHWWZT5O1d1a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai --upgrade"
      ],
      "metadata": {
        "id": "vbMaqBap5iJn",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== IMPORT LIBRARIES ==========\n"
      ],
      "metadata": {
        "id": "hLd5xDlVchVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from openai import OpenAI\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "_dpUL0C50ehw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== CONFIGURATION ==========\n"
      ],
      "metadata": {
        "id": "K__CWTKRctgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key=\"YOUR-API-KEY\"\n",
        ")\n",
        "EMBED_MODEL = 'paraphrase-multilingual-MiniLM-L12-v2'\n",
        "CHAT_MODEL  = 'gpt-4.1'\n",
        "K           = 10"
      ],
      "metadata": {
        "id": "ZVyZ_FWLenBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== SYSTEM PROMPT DEFINITION ==========\n"
      ],
      "metadata": {
        "id": "mu8Xsp0BeoJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = (\"\"\"You are an expert French medical annotator.\n",
        "\n",
        "═════════ TASK ═════════\n",
        "1. Read the input French text.\n",
        "2. Insert XML tags **in-line** around every entity mention according to the label definitions provided.\n",
        "   → Example: Le <INF_DISEASE>paludisme</INF_DISEASE> est endémique.\n",
        "3. Return **only** the full annotated text. No commentary, no metadata.\n",
        "\n",
        "→ Think step by step **internally**, but output only the final tagged text.\n",
        "\n",
        "═════════ ANNOTATION RULES ═════════\n",
        "• Use only the labels from the glossary.\n",
        "• Exclude determiners, pronouns, and punctuation from entity spans.\n",
        "• If an entity is **discontinuous**, tag **each contiguous part separately** with the same label and shared `ent_id`.\n",
        "   → Ex: les <PATHOGEN ent_id=\"P1\"><PATHOGEN ent_id=\"P2\">virus</PATHOGEN></PATHOGEN> de la <PATHOGEN ent_id=\"P1\">dengue</PATHOGEN> et du <PATHOGEN ent_id=\"P2\">chikungunya</PATHOGEN>\n",
        "    <ORGANIZATION ent_id=\"O1\">Agence régionale de santé</ORGANIZATION> (<ORGANIZATION ent_id=\"O2\">ARS</ORGANIZATION>) <ORGANIZATION ent_id=\"O1\"><ORGANIZATION ent_id=\"O2\">d’Île de France</ORGANIZATION></ORGANIZATION>\n",
        "• Tags must not cross paragraph boundaries.\n",
        "• Ignore misspellings, generic terms (\"virus\", \"bactérie\", etc.), and pronouns.\n",
        "• Do **not** generate any tag that does not exist in the input.\n",
        "• Use valid XML syntax. Tags must be correctly opened/closed and perfectly nested.\n",
        "• Overlapping tags are allowed **only** for discontinuous spans (as shown above).\n",
        "\n",
        "═════════ LABEL GLOSSARY ═════════\n",
        "✔ = tag it ✘ = don’t tag it\n",
        "\n",
        "→ **Document-level metadata**\n",
        "• DOC_AUTHOR ✔ \"Jean Dupont\" (byline only) ✘ in body\n",
        "• DOC_SOURCE ✔ \"AFP\", \"Reuters\" ✘ \"la presse\"\n",
        "\n",
        "→ **Diseases & Pathogens**\n",
        "• INF_DISEASE ✔ grippe, rougeole ✘ \"maladie\", \"infection\"\n",
        "• NON_INF_DISEASE ✔ cancer, diabète ✘ syndromes mixtes\n",
        "• PATHOGEN ✔ Escherichia coli, virus Ebola ✘ \"virus\" (generic)\n",
        "• DIS_REF_TO_PATH ✔ paludisme in “parasites tels que le paludisme” ✘ paludisme as disease\n",
        "• PATH_REF_TO_DIS ✔ VIH in “cas de VIH” ✘ virus VIH\n",
        "\n",
        "→ **Toxins, Chemicals, Explosives**\n",
        "• RADIOISOTOPE ✔ uranium 238, césium-137\n",
        "• TOXIC_C_AGENT ✔ sarin, chlore gazeux\n",
        "• EXPLOSIVE ✔ TNT, RDX\n",
        "• BIO_TOXIN ✔ ricine, toxine botulique\n",
        "\n",
        "→ **Locations & Organizations**\n",
        "• LOCATION ✔ Paris, Rhône, Alpes ✘ pronouns, \"le pays\"\n",
        "• ORGANIZATION ✔ OMS, hôpital Georges-Pompidou\n",
        "• LOC_REF_TO_ORG ✔ Paris (dans “Paris annonce…”)\n",
        "• ORG_REF_TO_LOC ✔ centrale nucléaire de Tchernobyl\n",
        "\n",
        "→ **Dates & Time References**\n",
        "• ABS_DATE ✔ 8 janvier 2025, 01/08/2025\n",
        "• REL_DATE ✔ hier, lundi dernier, 8 janvier (sans année)\n",
        "• DOC_DATE ✔ date en tête d’article\n",
        "• ABS_PERIOD ✔ mars 2024, du 1er au 3 mai 2024\n",
        "• REL_PERIOD ✔ la semaine dernière, du 10 au 20 mai\n",
        "• FUZZY_PERIOD ✔ ces dernières années, depuis plusieurs semaines\n",
        "\n",
        "═════════ CONSTRAINTS ═════════\n",
        "1. Output must contain **valid XML** with correct nesting.\n",
        "2. A token may belong to multiple tags **only** when discontinuity requires it.\n",
        "3. Never output tags for absent entities or unsupported labels.\n",
        "\n",
        "═════════ EXAMPLES ═════════\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "7QoPu59acleO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== LOAD DATA ==========\n"
      ],
      "metadata": {
        "id": "X6KW6g8Ie3mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test set (texts to annotate)\n",
        "with open('20250516_NP_test_evalLLM.json', 'r', encoding='utf-8') as f:\n",
        "    test_data = json.load(f)\n",
        "test_texts = [d['text'] for d in test_data]\n",
        "\n",
        "# Load training set (few-shot pool) with tagged XML outputs\n",
        "with open('20250428_NP_train-evalLLM_XML.json', 'r', encoding='utf-8') as f:\n",
        "    train_data = json.load(f)\n",
        "train_texts = [d['text'] for d in train_data]\n",
        "train_tagged = [d['tagged_text'] for d in train_data]\n"
      ],
      "metadata": {
        "id": "NjiTyKZ4Yc-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== COMPUTE EMBEDDINGS ==========\n"
      ],
      "metadata": {
        "id": "HPmTUanbfFz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence embeddings for similarity-based retrieval\n",
        "embedder = SentenceTransformer(EMBED_MODEL)\n",
        "test_embeddings = embedder.encode(test_texts, convert_to_numpy=True)\n",
        "train_embeddings = embedder.encode(train_texts, convert_to_numpy=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "83wOwtXFfGNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== SELECT FEW-SHOT EXAMPLES BY SIMILARITY ==========\n"
      ],
      "metadata": {
        "id": "3ZJpCvSdfTEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_similar(test_emb, train_embs, k=10):\n",
        "    sims = cosine_similarity([test_emb], train_embs)[0]\n",
        "    return np.argsort(sims)[-k:][::-1]\n",
        "\n"
      ],
      "metadata": {
        "id": "cxxLoonnfItX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== BUILD BATCH TASKS FOR OPENAI CHAT COMPLETION ==========\n"
      ],
      "metadata": {
        "id": "aM4vZxrIfayD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tasks = []\n",
        "for i, (text, emb) in enumerate(zip(test_texts, test_embeddings)):\n",
        "    neighbors = top_k_similar(emb, train_embeddings, k=10)\n",
        "\n",
        "    # Format few-shot examples\n",
        "    few_shot = [\n",
        "        f\"INPUT: {train_texts[nb]}\\nOUTPUT: {train_tagged[nb]}\"\n",
        "        for nb in neighbors\n",
        "    ]\n",
        "    prompt_with_few_shot = SYSTEM_PROMPT + \"\\n\\n\" + \"\\n\\n\".join(few_shot)\n",
        "    user_content = f\"INPUT: {text}\\nOUTPUT:\"\n",
        "\n",
        "    # Build the OpenAI API request\n",
        "    tasks.append({\n",
        "        \"custom_id\": f\"task-{i}\",\n",
        "        \"method\": \"POST\",\n",
        "        \"url\": \"/v1/chat/completions\",\n",
        "        \"body\": {\n",
        "            \"model\": CHAT_MODEL,\n",
        "            \"temperature\": 0,\n",
        "            \"messages\": [\n",
        "                {\"role\": \"system\", \"content\": prompt_with_few_shot},\n",
        "                {\"role\": \"user\",   \"content\": user_content}\n",
        "            ]\n",
        "        }\n",
        "    })"
      ],
      "metadata": {
        "id": "NPbrlSEHfLc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== SAVE BATCH TASKS TO JSONL ==========\n"
      ],
      "metadata": {
        "id": "u_9s_TLGfm8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"batch_evalLLM.jsonl\"\n",
        "\n",
        "with open(file_name, 'w') as file:\n",
        "    for obj in tasks:\n",
        "        file.write(json.dumps(obj) + '\\n')"
      ],
      "metadata": {
        "id": "WyQI_EknHpcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== SUBMIT BATCH TO OPENAI API ==========\n"
      ],
      "metadata": {
        "id": "Hue3IE61fpTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload batch file for processing\n",
        "batch_file = client.files.create(\n",
        "  file=open(file_name, \"rb\"),\n",
        "  purpose=\"batch\"\n",
        ")"
      ],
      "metadata": {
        "id": "Yl7z_KJRHqPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the batch job\n",
        "batch_job = client.batches.create(\n",
        "  input_file_id=batch_file.id,\n",
        "  endpoint=\"/v1/chat/completions\",\n",
        "  completion_window=\"24h\"\n",
        ")"
      ],
      "metadata": {
        "id": "xDPalaEgHwOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally: print job info and status\n",
        "batch_job = client.batches.retrieve(batch_job.id)\n",
        "print(batch_job)\n",
        "batch_job.status"
      ],
      "metadata": {
        "id": "yKtM6A4EHx_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== RETRIEVE BATCH OUTPUT ==========\n"
      ],
      "metadata": {
        "id": "E33CIw8lf9bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_file_id = batch_job.output_file_id\n",
        "result = client.files.content(result_file_id).content"
      ],
      "metadata": {
        "id": "PMm2ZJmhH2LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_file_name = \"batch_job_results_evalLLM.jsonl\"\n",
        "\n",
        "with open(result_file_name, 'wb') as file:\n",
        "    file.write(result)"
      ],
      "metadata": {
        "id": "sY87MiSHH4yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== PARSE RESULTS AND BUILD FINAL OUTPUT ==========\n"
      ],
      "metadata": {
        "id": "dnPnhuOIgEA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "with open(result_file_name, 'r') as file:\n",
        "    for line in file:\n",
        "        json_object = json.loads(line.strip())\n",
        "        results.append(json_object)"
      ],
      "metadata": {
        "id": "YdIwB-fyH5fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        "for res in results:\n",
        "    cid = res[\"custom_id\"]\n",
        "    idx = int(cid.split(\"-\")[1])\n",
        "    result = res['response']['body']['choices'][0]['message']['content']\n",
        "    item=test_data[idx]\n",
        "    l.append({\n",
        "        \"text\": item['text'],\n",
        "        \"prediction\":  result,\n",
        "    })"
      ],
      "metadata": {
        "id": "DHtZxyKuH7aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ========== SAVE FINAL PREDICTIONS TO FILE ==========\n"
      ],
      "metadata": {
        "id": "4v0XCGmegJJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('YOUR-OUTPUT-FILE', 'w', encoding='utf-8') as f:\n",
        "    json.dump(l, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "XKhoRL16gJk3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
